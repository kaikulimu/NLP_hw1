README for Homework 1

Part 1 - 10 sample sentences:

is it true that a chief of staff with a sandwich with every chief of staff in a floor in every pickle with
a floor in every perplexed floor in the floor in the floor in a president with every floor on a pickle under
every pickle with every chief of staff in a pickle in a sandwich in the floor under every floor ate a pickled
chief of staff ?
a pickle ate every president on every perplexed sandwich on every perplexed chief of staff with the preside
nt in every floor in every pickle on the president in a pickle in a president !
is it true that every floor under every floor under the sandwich under the floor with the perplexed chief o
f staff on the fine fine pickle in every pickle under the chief of staff on a sandwich in the chief of staf
f under every president on a pickle with every president in the pickled chief of staff understood every flo
or in every sandwich on the chief of staff in every pickled pickle ?
every delicious pickle kissed the sandwich in the pickle on every pickled chief of staff under a floor under
a fine sandwich with every perplexed chief of staff .
is it true that a chief of staff wanted the pickled fine president ?
is it true that a perplexed chief of staff pickled a pickle ?
every president ate the sandwich in the sandwich with every floor with the pickled sandwich with the floor
with a floor !
is it true that a sandwich understood a president on every chief of staff ?
is it true that a pickle under every president pickled every sandwich ?
the president pickled a delicious pickled perplexed pickled pickled chief of staff !


2. (a) The sentences tend to be long because of the rule NP --> NP PP because it goes into
       loops of adding a noun phrase with an extra prepositional
       phrase that always adds another noun phrase. Every time you have a noun
       phrase you have a 50% probability of effectively adding another noun phrase since the only
       other noun phrase rule is NP --> Det Noun, which is equally likely.
   (b) The probability of choosing the Noun --> Adj Noun rule is only 1/6, and this is the only way
       to generate adjectives.
   (c) -- code adjusted in RandSent.java to accommodate probabilities --
   (d) To fix (a) you must make the NP --> Det Noun have a larger probability than
       NP --> NP PP. To fix (b) you must increase the probability of Noun --> Adj Noun
       so that terminals drastically more likely anymore.
   (e) I adjust the frequencies of various terminals like nouns such that it was more indicative
       of our personal experience with real life English sentences.

is it true that the perplexed floor kissed the perplexed chief of staff ?
every president wanted the delicious president .
the floor wanted the chief of staff .
a fine fine pickle with a chief of staff on a chief of staff pickled the fine floor .
the chief of staff understood the chief of staff !
is it true that the president kissed every chief of staff in the fine fine fine chief of staff ?
is it true that the chief of staff understood every perplexed president on every president ?
the chief of staff ate a pickle .
is it true that the floor in the fine sandwich pickled the fine chief of staff ?
is it true that every chief of staff understood a fine pickled president in every fine floor ?


3. -- generate and display 10 sentences using grammar3.txt --
   (a) I added a proper noun nonterminal that only had the terminal 'Sally': NP --> PNoun, PNoun --> Sally
   (b) I added a conjunction nonterminal to verb phrases and noun phrases and added the terminal 'and':
       VP --> Verb Conj VP, VP --> VP Conj VP, NP --> NP Conj NP, Conj --> and
   (c) I created an intransitive verb nonterminal called
   (d)
   (e)
   (f)
   (g)
   (h)

is it true that every floor and Sally wanted every pickle and sighed ?
every perplexed chief of staff understood Sally .
is it true that it perplexed the perplexed fine floor that every floor pickled a pickle and ate Sally ?
a desk ate Sally and Sally and every pickle and pickled the floor .
that it perplexed Sally that the very pickled fine pickle in the fine president understood Sally in a desk perplexed Sally .
that every president with a president pickled every proposal on the perplexed president perplexed the president in Sally !
the proposal pickled Sally under the pickled floor .
the very fine very delicious president sighed !
is it true that every pickle under the pickle on every floor and Sally understood and understood and kissed and wanted every delicious sandwich ?
is it true that Sally sighed ?

4. -- see adjustments in RandSent.java --

5. (a) The alternative derivation is as follows:
	   
	   (ROOT (S (NP (NP (Det every)
	   				    (Noun sandwich))
	                (PP (Prep with)
					    (NP (NP (Det a)
							    (Noun pickle))
						    (PP (Prep on)
							    (NP (Det the)
								    (Noun floor))))))
	            (VP (V wanted)
				    (NP (Det a)
					    (Noun president))))
			  .)

   (b) Each derivation has a different meaning. The first derivation 
       suggests that it's the sandwiches with pickles that are both on
	   the ground and wanting a president. The second derivation says 
	   that sandwiches want a president when their pickles are on the 
	   floor. The main difference is in which noun phrase 'on' is modifying.

6. (a) Sometimes it will find an alternative. This is because some sentences
	   are ambiguous, meaning that they can be derived using more than one
	   set of steps. It will likely "misunderstand" by choosing the most
	   likely sentence parsing even if you intended the sentence to have
	   a parsing that is more rare.

   (b) There are 5 ways to analyze the noun phrase. You can verify this by
       breaking the noun phrase up into its 4 sub-noun phrases with 
	   3 prepositions that have to compose with a neighboring noun phrase
	   of some sort. So if you number the sub-noun phrases 1 (every sandwich),
	   2 (a pickle), 3 (the floor), and 4 (the chief of staff) then you can
	   count all the ways to connect them in a binary tree where they must
	   read in order from left to right. Every intermediate node is an NP
	   resulting from joining to sub-NPs by a preposition. So to count the 
	   number of ways you can interpret the sentence, you start by composing 1
	   and 2 first to yield NP1. Then you can either choose to compose NP1 with
	   3 before composing with 4 which is our first full NP interpretation, or 
	   you can compose 3 and 4 first to yield NP2 and then compse NP1 and NP2.
	   The third interpretation is the mirror of the first, so you would 
	   compose 3 and 4 first to yield NP3 and then compose NP3 with 2 before
	   composing with 1. The fourth interpretation requries starting by
	   composing 2 and 3 first to yield NP4 then composing NP4 with 1 before 
	   composing with 4. The fifth and final interpretation is just the mirror
	   of the fourth, in that you still compose 2 and 3 first, but this time 
	   you compose the NP4 they yield with 4 before composing with 1.

   (c) We noticed that the number of parses directly correlates with the number
       of prepositions in the NP in question.

	   number of parses: 		1, 2, 5, 14, 42, 132
	   number of prepositions: 	1, 2, 3,  4,  5,   6

	   We find this pattern to fit Catalan Numbers. It reflects the very
	   recursive nature of natural language.

	   ***********************conjunctions in grammar 3*************************

   (d) i. the president ate the sandwich .
          The probability is so small because it is derived from the many outcomes from a
          multi-layer tree with many branches on each layer.
          The probability 5.144e-05 comes from multiplying the probabilities as follows:
          First, the probability that a sentence is in the structure "S ." as opposed to "S ?"
          and "is it true that S ?" is 1/3. Then, S . consists of NP VP which is essentially
          NP Verb NP. There are 5 choices for verb so the probability that it is "ate" is 1/5.
          For Noun Phrases, there is a 50% chance that is is simply "Det Noun". Then, since
          there are 3 determiners and 6 noun rules, the probability that it is "the president"
          is 1/36. Same for "the sandwich". Thus in total the probability is:
                            1/3 * 1/5 * 1/36 * 1/36 = 5.144e-05

          Since there is only one possible derivation of this sentence, the probability of
          generating this sentence is equal to the probability of generation the best derivation.

          Which is also the reason why p(best_parse|sentence) = 1.



7. (b) Yes-no questions
   (c) Relative clauses